\documentclass[a4paper,draft]{scrartcl}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{arrows, positioning}
\usepackage{pgf-umlcd}
\title{Entwicklerdokumentation pyPsy}
\author{Franz Gregor und Alexandra Weiss}
\date{\today}
\makeindex

\begin{document}
\pagenumbering{arabic}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Projektziel}
In der Arbeitsgruppe "Angewandte Kognitionsforschung des Instituts f\"ur Psychologie III der Fakult\"at f\"ur Mathematik und Naturwissenschaften der Technischen Universtit\"at Dresden wird die Aufmerksamkeit des Menschen untersucht.
Dazu werden unter Anderem Experimente bei dennen Probanten einen Eye-Tracker tragen durchge\"uhrt.

Den Eye-Tracker kann man sich als \"ubergrosse, mit mehereren Kameras ausgestattete Brille vorstellen.
Diese Kameras nehmen zum einem das Blickfeld des Probanden sowie seine Augen auf.
Aus den Aufnahmen der Augen errechnet das Eye-Tracking-System die Blickrichtung des Probanden.
Und liefert nach dem Versuch ein Rohvideo, das das Blickfeld des Probanden zeigt und eine Datei mit den bin\"ar gepeicherten Rohblickdaten.
Diese beiden Dateien k\"onnen mit Hilfe eines Tools des Herstellers des Eye-Tracking-Systems in ein Video mit Overlay und eine ASCII Datei mit genauen Informationen \"uber das Blickverhalten des Probanden umgewandelt werden.
Das Video mit Overlay ist zeigt das Blickfeld des Probanden und einen blauen Punkt an der Stelle auf die Proband gerade sieht.

F\"ur die Auswertung der Experimente ist es vor allem interessant was der Proband wann wahrgenommen hat.
Um diese Information ohne weitere Hilfsmittel zu erhalten m\"ussen mindestens das Video mit Overlay und die ASCII Datei mit den Blickdaten gleichzeitg betrachtet werden.
Ausserdem m\"ussen die Daten erfasst werden.
Was dazu gef\"uhrt hat das die Wissenschaftler mit Stift und Block vor dem Computer sassen und lange Stunden die Videos ausgewertet haben.

Dieser Prozess soll mit Hilfe des zu entwicklenden Programms vereinfacht werden.

\section{Beschreibung}
Die Aufgabe von pyPsy ist es, den Benutzer bei der Verwertung von Eyetracking Daten zu untersützen. Konkret wird der von der Besuchsperson betrachtete Punkt als farbiges Overlay in das Video gezeichnet, sodass eine Auswertung in Form einer Kategorisierung durchgeführt werden kann. Dabei wird die Kategorisierung der betrachteten Gegenstände in pyPsy eingetragen und kann dann als csv-Datei abgespeichert werden, wodurch eine genaue Aufschlüsselung der Häufigkeiten möglich ist. 
Um die Augenbewegungsdaten in pyPsy auslesen zu können, müssen diese vorher in eine *.asc Datei exportiert werden. Liegt eine solche Datei für ein Video vor, so können beide Dateien in pyPsy geladen und bearbeitet werden.
Innerhalb einer *.asc Datei gibt es mehrere Trials, die gesondert voneinander betrachtet werden.

\section{Architektur}
pyPsy ist eine Multiprocessing Anwendung.
Das bedeutet, dass mehrere unabh\"angige Prozesse miteinander arbeiten um die gesamte Funktionalit\"at bereit zu stellen.
Wir haben uns f\"ur diese Architektur entscheiden, weil in einem Videoplayer mindestens zwei ???PROGRAMML\"aufe existieren, ein WiedergabePROZESS, der das Video "abspielt" und ein PROZESS der auf Aktionen des Benutzers reagiert (Wiedergabe stoppen, etc.), und w\"arend der Machbarkeitsuntersuchungen hat sich herausgestellt, dass diese PROZESSE in Python nicht durch Threads repr\"asentiert werden k\"oennen.
Der Grund daf\"ur liegt in der Implementierung von Threads in Python per GIL("`Global Interpreter Lock'") und der daraus resultierenden nicht ausreichenden Performance der Threadingl\"osung.

Wir trennen die Anwendung in zwei Prozesse mit jeweils unterschiedlichen Aufgaben auf.
Der erste Prozess k\"ummert sich um die Nutzerinterarktion und damit haupts\"achlich um die GUI.
Der zweite Prozess \"ubernimmt die fachlichen Aufgaben. Das sind z.B. das Videobild samt Overlay bereitstellen oder die Kategoriesierungen verwalten und exportieren.
Der erste Prozess wird nachfolgend GUI-Prozess, der zweite Prozess Backend-Prozess genannt.
Die Programmkontrolle geht in aller Regel vom GUI-Prozess aus.
In den folgenden Abschnitten wird die Controller Komponente n\"aher beschrieben.
Diese ist gewisserma\ss en das Interface zum Backend-Prozess.

\section{Komponenten}
In diesem Abschnitt werden die wichtigsten Komponenten von pyPsy und deren Interaktion beschrieben.

\subsection{GUI}
Die folgenden Komponenten stellen die GUI oder ihre Elemente bereit und werden im GUI-Prozess ausgef\"uhrt.
Diese Liste ist nicht vollst\"andig.
Sie betrachtet nur die interessantesten Konzepte.

\subsubsection{MainFrame}
Der MainFrame ist das Hauptfenster von pyPsy, in dem der Benutzer das Video sehen und steuern kann. Des weiteren werden die bereits vorgenommenen Kategorisierungen auf der rechten Seite in der CategoryList angezeigt. Die Spalte Index bezeichnet entweder den Index des Frames oder - je nach EinCategoryListstellung des Projekts - der Fixation im Video, während rechts daneben der Name der Kategorie eingetragen wird. 
Direkt unter dem Bild des Videos ist ein Slider, mit dem der Benutzer Frame genau durch das Video navigieren kann.
Unterhalb des Bildes vom Video sind Buttons für die Steuerung der Wiedergabe des Videos. Von links nach rechts sind dies
\begin{itemize}
\item Frame zurück springen
\item Play
\item Pause
\item Frame nach vorne springen
\item zum/r nächsten nicht kategorisierten Frame/Fixation springen
\end{itemize}
Daneben sind Checkboxen mit denen der Benutzer festlegen kann, welche Augendaten im Video angezeigt werden sollen. Dabei steht
\begin{itemize}
\item L für Daten des linken Auges
\item R für Daten des rechten Auges
\item M für die Mittelung der Daten beider Augen
\end{itemize}
Rechterhand unter der Liste der Kategorisierungen befindet sich der Speed Slider, mit dem der Benutzer die Abspielgeschwindigkeit des Videos einstellen kann. 
In der Status Bar rechts am unteren Ende des Fensters werden alle relevanten Informationen für einen besseren Überblick angezeigt. Der Reihe nach sind diese:
\begin{itemize}
\item angezeigte Augendaten (eingestellt durch die Checkboxen)
\item ob Fixationen oder Frames kategorisiert werden
\item Abspielgeschwindigkeit des Videos
\item bereits verstrichene Zeit des Videos
\item Länge des Videos
\item aktuelle/r Frame/Fixation 
\item Anzahl Frames/Fixationen des Videos
\end{itemize}
Die Menüs oben links bieten dem Benutzer folgende Untermenüs:
Das "`File'" Menü ist unterteilt in "`Open'", "`Save'", "`About'" und "`Quit'". 
Im "`Category'" Menü mit den Punkten "`Mange categories'" und "`Export categories'" kann der Benutzer Kategorien anlegen und verwalten. Dies schließt den Import von Kategorien aus anderen pyPsy-Projekten ein.
Im Menüpunkt für den Export können die vorgenommenen Kategorisierungen als .csv-Datei exportiert werden. 
Das"`Export'" Menü mit dem Unterpunkt "`Video'" ist für den Videoexport zuständig. Wird dieser Menüpunkt ausgewählt, so muss der Benutzer zunächst den Pfad und den Namen für die resultierende .avi-Datei angeben. Der Fortschritt des Exports wird in einem Fortschrittsfenster angezeigt.


\subsubsection{CategoryList}
Auf der rechten Seite des MainFrames werden die bereits vorgenommenen Kategorisierungen angezeigt, sobald der Benutzer diese vornimmt. 
Da entweder Frames oder Fixationen kategorisiert werden, werden als Index links von den Kategorienamen die Indices der Frames oder Fixationen angezeigt. Ist ein/e Frame/Fixation noch nicht kategorisiert, wird nur ein Strich angezeigt.
Um eine Folge von Frames oder Fixationen zu kategorisieren, kann nach Anwendung einer Kategorie auf einen Index diese Kategorie durch drücken der Pfeiltaste nach unten diese Kategorie auch auf die folgenden Indices angewendet werden.
Falls nötig, können Kategorisierungen gelöscht werden, indem die entsprechenden Indices markiert werden und die Entfernen Taste gedrückt wird. 

\subsection{Backend}
Die Komponenten in diesem Abschnitt werden im Backend genutzt.
Das hei\"\ss t sie stellen die fachliche Funktionalit\"at her.

\subsubsection{Controller}
  Der Controller spielt eine sehr zentrale Rolle in pyPsy, da er die Schnittstelle zwischen GUI und den funktionalen Klassen bildet. Im Sinne des Design Patterns "`Model-View-Controller"' bedeutet dies, dass Klassen, die die GUI verwalten auf beispielsweise die Clock nur über den Controller zugreifen können. Im Folgenden ist der Zugriff der GUI-Klassen auf den Controller beziehungsweise der funktionalen Klassen auf den Controller dargestellt.
  \begin{figure}[ht]
    \begin{center}
    \begin{tikzpicture}[auto, node distance=1.2cm]
      \node (controller) {Controller};    
      \node[right=2.2cm of controller] (clock) {Clock};
      \node[above of=clock] (categories) {CategoryContainer};
      \node[above of=categories] (eyes) {EyeMovement};
      \node[above of=eyes] (saveable) {Saveable};  
      \node[below of=clock] (vid_reader) {VideoReader};
      \node[below of=vid_reader] (vid_writer) {VideoWriter};
      \node[below of=vid_writer] (cfg) {Config};
      \node[below of=cfg] (help) {Helper};
        
      \node[left=2.2cm of controller](mainframe) {MainFrame};     
      \node[above of= mainframe] (editcatdlg) {EditCategoryDialog};
      \node[above of= editcatdlg] (catdlg) {CategoryDialog};
      \node[above of= catdlg] (opendlg) {OpenDialog};
      
      \node[below of= mainframe] (categorylist) {CategoryList};      
      \node[below of= categorylist] (strimage) {StringImage};
      \node[below of= strimage] (cursors) {images};

      \path
	(controller) edge (clock)
	(controller) edge (vid_reader)
	(controller) edge (vid_writer)
	(controller) edge (eyes)
	(controller) edge (categories)
	(controller) edge (cfg)
	(controller) edge (help)
	(controller) edge (saveable)
	(controller) edge (mainframe)
	(controller) edge (categorylist)
	(controller) edge (opendlg)
	(controller) edge (catdlg)
	(controller) edge (editcatdlg)
	(controller) edge (strimage)
	(controller) edge (cursors)
      ;
    \end{tikzpicture}
    \end{center}
  \caption{Verwendete Klassen und Rolle des Controllers}
  \label{Grobentwurf}
  \end{figure}
  
  Die Besonderheit dieser Model-View-Controller Architektur ist, dass es nur einen zentrallen Controller gibt. Dadurch soll der Implementationsaufwand minimiert werden. Auf der rechten Seite sind die Models angeordnet, in der Mitte der Controller und auf der linken Seite die Views. Im folgendem wird kurz auf die Aufgaben der einzelnen Models eingegangen. Die Views bieten dem Nutzer jeweils die Interaktionsmöglichkeit an und der Controller setzt diese auf die Models um.

\subsubsection{Savable}

\subsubsection{Clock}
Diese Klasse ist der programminterne Zeitgeber. 
Das bedeutet, sie enthält in erste Linie den aktuellen Zeitpunkt des Programms in Bezug auf das Video beziehungsweise die Augenbewegungsdaten.

Alle Komponenten greifen direkt oder indirekt auf diese Instanz zurück wenn sie eine zeitveränderliche Eigenschaft abrufen. Daher gehen alle zeitlichen Steuerbefehle an die Instanz dieser Klasse, wie beispielsweise nächstes Frame oder vorherige Fixation. 

Zeitabhängige Komponenten können über die Funktion $register(function)$ gemäß des "`Observer Patterns"' über eine Veränderung der Zeit informiert werden.
Mit dieser Funktion wird biepsielsweise die GUI darüber informiert, dass sie das gezeigte Bild aktualisieren muss.

\subsubsection{VideoReader}
Die VideoReader Klasse ist für den Zugriff auf die Videobilder zuständig.

Der Klasse wird bei der Initialisierung der Ort der Videodatei bekannt gegeben und anschließend bietet sie framegenauen Zugriff und Informationen zum geladenen Video.

\subsubsection{VideoWriter}
Diese Klasse nimmt einzelne Bilder entgegen und speichert sie in einer Videodatei ab.

Dazu erhält sie bei der Initialisierung den Pfad der zu erstellenden Videodatei, die gewünschte Anzahl der Bilder pro Sekunde und den zu verwendenden Videocodec.
Das zu verwendende FOURCC Videocodec kann in der Konfigurationsdatei angegeben werden. Es ist wichtig, dass das angegebene FOURCC Codec auf dem System instaliert ist und der FOURCC Name korrekt ist. Ist dies nicht der Fall, erscheint eine Fehlermeldung.

\subsubsection{CategoryContainer}
Die CategoryContainer Klasse hält die Kategorien sowie die Zuordnung von Fixationen oder Frames zu Kategorien.

Bei der Initialisierung der Klasse wird festgelegt ob sie Fixationen oder Frames zu Kategorien zuordnet.

Anschließend bietet die Instanz Methoden, um die Kategorien zu verwalten (anlegen, Namen oder Tastenkürzel ändern, löschen), eine Fixation oder ein Frame einer Kategorie zuzuordnen, die Zuordnungen zu exportieren und um auf die beinhalteten Daten zuzugreifen.

\subsubsection{EyeMovement}
Die EyeMovement Klasse bereitet die Augenbewegungsdaten auf und bietet sie anderen Komponenten des Programms an.

Nachdem der Klasse bei der Initialisierung der Pfad zu einer Augenbewegungsdatendatei übergeben wurde, parst sie diese Datei und legt die enthaltenen Daten in internen Datenstrukturen an. Nun können andere Komponenten den Zustand der Augen zu einem bestimmten Zeitpunkt kategorisieren. Konkret kann folgendes abgerufen werden: Blickposition, Sakkade, Fixation oder Blinzeln jeweils des linken und rechten Auges und gemittelt für beide Augen.

\section{M\"ogliche Erweiterung}
  \begin{description}
    \item[Deinteralicing] Blablabla, opencv y u no deinterlacing?
    \item[Autosave Dialog] nicht aufmachen während Video Export?
  \end{description}

\section{Verwendete Python Module}
In den folgenden Abschnitten werden verwendete Python Module aufgezählt und kurz erklärt, wofür diese konkret in pyPsy verwendet werden. Dabei werden nur die Module erwähnt, die für die Funktionalität von pyPsy direkt notwendig sind und nicht häufig verwendete Module wie beispielsweise das "`os"' Modul. 
\subsection{OpenCV für Python}
Für die Verarbeitung von Videodateien und allen dazugehören Operationen wird OpenCV für Python verwendet, da es sehr viele Möglichkeiten bietet, gut dokumentiert und außerdem performant ist. 
Im Einzelnen wird OpenCV für das framebasierte Einlesen des Ausgangsvideos, das Zeichnen des Overlays (also der Augdaten) und das Erzeugen eines neuen Videos mit Overlay verwendet.
\subsection{Multiprocessing und Threading}
Diese beiden Module gewährleisten eine bessere Auslastung der Systemressourcen da sie mehrere gleichzeitige Verarbeitungsprozesse erm\"oglichen. In pyPsy sind das Beispielsweise gleichzeitiges Reagieren auf Nutzereingaben (z.B. Kategorisierung) w\"ahrend der Videowiedergabe.
Im Backend verwenden wir Threading um den internen Zeitgeber weiter zu setzen und gleichzeitig Anfragen der GUI (des Benutzers) abarbeiten zu k\"onnen.
In der Clock Klasse wird Threading verwendet, um einen nur für die Clock zuständigen Thread zu erzeugen. Dieser Thread bestimmt außerdem die Zeitrechnung der Clock, indem er für ein gewisses Interval schläft und erst danach weiter tickt. 

Das Multiprocessing Packet wird in der Startroutine von pyPsy verwendet, um die performante Nebenl\"aufigkeit der Prozesse (GUI und Backend) in pyPsy zu gew\"ahrleisten. Dabei wird der Controller als Adapter zwischen den Model (Backend) und den View (GUI) Klassen verwendet. Das bedeuted das die Kommunikation zwischen GUI und Backend nur \"uber die Methoden des Controllers stattfindet. Daf\"ur erh\"alt die GUI einen Proxy des Controllers. Welcher die Methodenaufrufe an die echte Controllerinstanz in einem anderem Prozess durch Interprozesskommunikation weiterleitet.

Da die Interprozzeskommunikation vergleichweise langsam ist werden die sich schnell \"andernten Bilddateien (Bild & Bildnummer) mit Hilfe eines gemeinsamen Speichers zwischen beiden Prozessen ausgetauscht.

F\"ur die Umsetzung der Interprozesskommunikation und des gemeinsamen Speichers haben wir auf die Standard Python Bibliothek zur\"uckgegriffen. Dieser k\"onnen auch weiter Informationen \"uber das Thema entnommen werden (\href{''http://docs.python.org/library/multiprocessing.html''})

\subsection{Json für Python}
Um die vom Benutzer editierbare Config-Datei auslesen und schreiben zu können, verwendet pyPsy das Json Modul. Dies geschieht in der Config un in der Saveable Klasse. 

\subsection{Pickle}
Das Picke Modul wird in der Saveable Klasse verwendet, um die vom Benutzer generierten Kategorisierungen gut lesbar in einer csv-Datei abzuspeichern. Das Modul übernimmt dabei einen großen Teil der Arbeit des sogenannten Pretty-Printings, also der Formatierung.

\end{document}
